{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cae04d6-767c-469f-99ba-7b60be5cf3de",
   "metadata": {},
   "source": [
    "# Generate AI summaries\n",
    "Use the ChatGPT API to generate summaries from OCR text. First chunk the document into 6000-character chunks, and get a summary of each chunk. Then, concatenate the summaries, chunk again, and repeat.\n",
    "\n",
    "\n",
    "\n",
    "Warning: you can run up nontrivial cost. Use with caution and avoid duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867654fa-1e4f-4382-8fb1-8b4fad5b526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import fitz\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() #load your custom environment variables from .env file in same directory\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad527335-f0a8-4e7b-ba2f-1009de78e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_structure(src, dst):\n",
    "    \"\"\"\n",
    "    Copies folder structure from src to dst without copying the files.\n",
    "    \"\"\"\n",
    "    for dirpath, dirnames, _ in os.walk(src):\n",
    "        structure = os.path.join(dst, os.path.relpath(dirpath, src))\n",
    "        if not os.path.exists(structure):\n",
    "            os.makedirs(structure)\n",
    "\n",
    "def summarize_chunk(chunk, model=\"gpt-4\"):\n",
    "    # Summarize a single chunk of text\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize the following text into two concise paragraphs: {chunk}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def summarize_text(text, model=\"gpt-4\"):\n",
    "    # Split the text into chunks to fit the token limit of the API\n",
    "    max_chunk_size = 6000  # Adjust this to ensure a balance between input size and output\n",
    "    chunks = [text[i:i+max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
    "\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarize_chunk(chunk, model=model)\n",
    "        summaries.append(summary)\n",
    "\n",
    "    # Now condense all the summarized chunks into one summary\n",
    "    final_summary_prompt = \"Condense the following summaries into a single paragraph with bullet points as needed: \" + ' '.join(summaries)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": final_summary_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Use tiktoken to count the number of tokens in the input text.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def process_files_in_folders(src, dst):\n",
    "    \"\"\"\n",
    "    Copy folder structure from src to dst and summarize text files in the source folder.\n",
    "    \"\"\"\n",
    "    create_folder_structure(src, dst)\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(src):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                \n",
    "                # Build the output path\n",
    "                relative_path = os.path.relpath(dirpath, src)\n",
    "                output_dir = os.path.join(dst, relative_path)\n",
    "                \n",
    "                if not os.path.exists(output_dir):\n",
    "                    os.makedirs(output_dir)\n",
    "                output_file = os.path.join(output_dir, filename.replace('.txt', '_summary.txt'))\n",
    "\n",
    "                if not os.path.exists(output_file): \n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        text_content = f.read()\n",
    "\n",
    "                    # Count tokens using tiktoken\n",
    "                    token_count = count_tokens(text_content, model=\"gpt-4\")\n",
    "                    print(filename+' token count: '+str(token_count))\n",
    "    \n",
    "                    # Summarize the content\n",
    "                    summary = summarize_text(text_content)\n",
    "                    if summary:\n",
    "                        summary = re.sub(r'[\\nâ€¢-]', ' ', summary)\n",
    "                        summary = re.sub(r'\\s+', ' ', summary).strip()\n",
    "                        summary = summary.replace('Sandia Heights Homeowners Association (SHHA)','SHHA')\n",
    "                        summary = summary.replace('Sandia Heights Homeowner Association (SHHA)','SHHA')\n",
    "                        summary = summary.replace('Sandia Heights Homeowner\\'s Association (SHHA)','SHHA')\n",
    "\n",
    "                        # Write the summary to the new file\n",
    "                        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                            f.write(summary)\n",
    "                else: \n",
    "                    print('already exists: '+file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc98c51a-c9a1-4d39-84ff-561f75c4ac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Swedish team won the gold medal in the men's curling event at the 2022 Winter Olympics. The Swiss team won the gold medal in the women's curling event.\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECK: an example question\n",
    "query = 'Which athletes won the gold medal in curling at the 2022 Winter Olympics?'\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        temperature=0,\n",
    "\n",
    "        messages=[\n",
    "        {'role': 'system', 'content': 'You answer questions about the 2022 Winter Olympics.'},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9bd731-d8f8-4945-9343-916fb5399959",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = '/Users/heidi/Documents/SHHA/GRIT/GRIT_archive_OCRtext/'  # Replace with the path to your folder\n",
    "destination_folder = '/Users/heidi/Documents/SHHA/GRIT/GRIT_archive_AI_summaries/'  # Replace with the path for the new folder structure\n",
    "\n",
    "process_files_in_folders(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23fb7f-7d26-46da-b084-ca0b730e4abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "chatgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
